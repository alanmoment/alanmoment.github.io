<!DOCTYPE html>
<html lang="en-us">
<head>

    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

  	<meta property="og:title" content=" Hadoop &middot;  Hello World!!" />
  	<meta property="og:site_name" content="Hello World!!" />
  	<meta property="og:url" content="http://localhost:1313/tags/hadoop/" />

    
    <meta property="og:type" content="website" />
    

  <title>
     Hadoop &middot;  Hello World!!
  </title>

    <meta name="description" content="you can do anything you want to do." />

    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="shortcut icon" href="http://localhost:1313/images/favicon.ico">
	  <link rel="apple-touch-icon" href="http://localhost:1313/images/apple-touch-icon.png" />

    <link rel="stylesheet" type="text/css" href="http://localhost:1313/css/screen.css" />
    <link rel="stylesheet" type="text/css" href="http://localhost:1313/css/nav.css" />
    <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic|Open+Sans:700,400|Inconsolata" />


    
      
          <link href="http://localhost:1313/index.xml" rel="alternate" type="application/rss+xml" title="Hello World!!" />
      
      
        <link href="http://localhost:1313/tags/hadoop/index.xml" rel="alternate" type="application/rss+xml" title="Hadoop &middot; Hello World!!" />
      
    
    <meta name="generator" content="Hugo 0.15" />

    <link rel="canonical" href="http://localhost:1313/tags/hadoop/" />

    

    
</head>
<body class="nav-closed">

  <div class="nav">
    <h3 class="nav-title">Menu</h3>
    <a href="#" class="nav-close">
        <span class="hidden">Close</span>
    </a>
    <ul>
        
        
        
            
            <li class="nav-opened" role="presentation">
            	<a href="http://localhost:1313/">Home</a>
            </li>
        
            
            <li class="nav-opened" role="presentation">
            	<a href="http://localhost:1313/page/about/">About me</a>
            </li>
        
    </ul>
    
    
    <a class="subscribe-button icon-feed" href="http://localhost:1313/tags/hadoop/index.xml">Subscribe</a>
    
</div>
<span class="nav-cover"></span>


 <div class="site-wrapper">




	<header class="main-header tag-head" style="background-image: url(http://localhost:1313//images/Iron_man.jpg)">

    <nav class="main-nav overlay clearfix">
      
        <a class="blog-logo" href="http://localhost:1313/"><img src="http://localhost:1313//images/517273.jpg" alt="Home" /></a>
      
      
          <a class="menu-button" href="#"><span class="burger">&#9776;</span><span class="word">Menu</span></a>
      
    </nav>
    <div class="vertical">
        <div class="main-header-content inner">
            <h1 class="page-title">Hadoop</h1>
            <h2 class="page-description">
                
            </h2>
        </div>
    </div>
</header>

<main class="content" role="main">
    

	<div class="extra-pagination inner">
    <nav class="pagination" role="navigation">
	
	<span class="page-number">Page 1 of 1</span>
	
</nav>

	</div>

	
	   
<article class="post post">
    <header class="post-header">
        <h2 class="post-title"><a href="http://localhost:1313/post/hadoop/shi_yong_sqoop_jiang_mysql_zi_liao_hui_ru_hbase/">使用Sqoop將MySQL資料匯入Hbase</a></h2>
    </header>
    <section class="post-excerpt">
        <p>想要使用MapReduce運算Hbase的資料，但若是原本資料在別種資料庫該怎麼辦呢，在龐大的Hadoop家族中Sqoop就是完成這一個任務，他有提供各種資料庫匯入至Hbase的功能。 因為我慣用MySQL所以還是拿MySQL當作範例，因為我是蠻久之前試玩的，所以是用舊的版本。他的安裝非常方便!! 安裝Sqoop $ cd /opt $ wget 'https://github.com/downloads/cloudera/sqoop/sqoop-1.2.0.tar.gz' 或是到官網下載 $ tar zxvf sqoop-1.2.0.tar.gz $ mv sqoop-1.2.0 sqoop 下載mysql-connector-java-5.1.15-bin.jar並複製到/opt/sqoop/lib，然後就完成囉!! 接下來就測試看看是否能正常運作。 測試Sqoop 列出資料表 $ /opt/sqoop/bin/sqoop list-tables --connect jdbc:mysql://127.0.0.1/test -P --username test 匯入資料表 $ /opt/sqoop/bin/sqoop import --connect jdbc:mysql://127.0.0.1/test --username test --table table_name --hive-import 匯入資料表時下WHERE $ /opt/sqoop/bin/sqoop import --connect jdbc:mysql://127.0.0.1/test --username test --table table_name --hive-import --query 'SELECT * FROM `table_name` where flow_no &gt; 1 AND flow_no 但是我測試過後...無法轉換換行阿..看官網是說sqoop 1.3才有支援，但是hadoop 0.20 並不支援sqoop 1.3一整個無言。改天再測試。 使用Sqoop有出現錯誤也可以顯示 $ /opt/sqoop/bin/sqoop import --connect jdbc:mysql://127.0.0.1/test --username test --table table_name --hive-import --verbose Demo 因為操作Sqoop是有點煩瑣的，所以我自己用PHP寫了Mysql匯入Hbase的簡單操作界面。 發生錯誤 無法從mysql匯入hbase 11/11/11 12:07:59 ERROR tool.ImportTool: Encountered IOException running import job: org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory table_name already exists 可以試試看刪除Hbase資料表 /opt/hadoop/bin/hadoop fs -rmr table_name 非單機模式下，必須寫成MySQL位址，不能用localhost --connect jdbc:mysql://mysqlserver_IP/databaseName 沒有資料庫的權限會發生下面的錯誤 11/11/11 23:22:13 INFO mapred.JobClient: Task Id : attempt_201111112316_0001_m_000004_0, Status : FAILED java.io.IOException: SQLException in nextKeyValue at com.cloudera.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:238) at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:423) at org.apache.hadoop.mapreduce.MapContext.nextKeyValue(MapContext.java:67) at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:143) at com.cloudera.sqoop.mapreduce.AutoProgressMapper.run(AutoProgressMapper.java:187) at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:621) at org.apache.hadoop.mapred.MapTask.run(MapTask.java:305) at org.apache.hadoop.mapred.Child.main(Child.java:170) Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Table 'test.tbl_skw_buyer' doesn't exist at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39) at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27) at java.lang.reflect.Constructor.newInstance(Constructor.java:513) at com.mysql.jdbc.Util.handleNewInstance(Util.java:407) at com.mysql.jdbc.Util.getInstance(Util.java:382) at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1052) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3603) at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3535) at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1989) at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2150) at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2626) at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:2119) at com.mysql.jdbc.PreparedStatement.executeQuery(PreparedStatement.java:2281) at com.cloudera.sqoop.mapreduce.db.MySQLDataDrivenDBRecordReader.executeQuery(MySQLDataDrivenDBRecordReader.java:50) at com.cloudera.sqoop.mapreduce.db.DBRecordReader.nextKeyValue(DBRecordReader.java:225) ... <a class="read-more" href="http://localhost:1313/post/hadoop/shi_yong_sqoop_jiang_mysql_zi_liao_hui_ru_hbase/">&raquo;</a></p>
    </section>
    <footer class="post-meta">
        
        
            <img class="author-thumb" src="http://localhost:1313//images/517273.jpg" alt="Author image" nopin="nopin" />
        
        
            Alan
        
        on
            
                <a href="http://localhost:1313/tags/hadoop/">#hadoop</a>,
            
        
        <time class="post-date" datetime="2013-07-18T14:54:00Z">
            18 Jul 2013
        </time>
    </footer>
</article>

	
	   
<article class="post post">
    <header class="post-header">
        <h2 class="post-title"><a href="http://localhost:1313/post/hadoop/shi_yong_mapreduce_zhi_ti_dai_fang_an_hive/">使用MapReduce之替代方案Hive</a></h2>
    </header>
    <section class="post-excerpt">
        <p>若要操作Hadoop就必須要會MapReduce，很好!!在Hadoop很夯之前相信很多人都對MapReduce非常陌生，沒錯!!那真的是有點困難，但是呢，若我講SQL語言，相信你一定信心十足吧!! 因此囉，Facebook當初也了這個問題傷透了腦筋，因為要找一個熟悉MapReduce的工程師比找一個會SQL語法的工程師還困難的情況底下，他們想出了應變之道，那就是用極接近SQL語言的方式去操作MapReduce，因為找到會SQL語言的人較容易。 所以Hive就是為此誕生的，這是Facebook一個部門的研發成果，後來為了讓更多人可以應用，他們將其釋出提供給Apache當作開源項目，讓Hive開始發揚光大，更多的介紹官網都有唷。 若你看不順眼Hive，你也可以選擇其他的諸如PIG(我不是在罵人&hellip;真的叫PIG)，或是你真的想挑戰MapReduce當然也可以，任君挑選。因為我喜歡Hive的Logo所以囉，我就選他了。 建立Hive 從官網下載或是 $ cd /opt $ wget 'http://ftp.stut.edu.tw/var/ftp/pub/OpenSource/apache//hive/hive-0.7.1/hive-0.7.1.tar.gz' $ mv hive-0.7.1 /opt/hive 安裝ivy $ cd /tmp $ wget 'http://www.apache.org/dist/ant/ivy/2.3.0/apache-ivy-2.3.0-bin-with-deps.tar.gz' $ tar zxvf apache-ivy-2.3.0-bin-with-deps.tar.gz $ mv apache-ivy-2.3.0 /usr/local $ ln -s apache-ivy-2.3.0 ivy 配置環境 $ vim ~/.bashrc export HIVE_HOME=/opt/hive export IVY_HOME=/usr/local/ivy export PATH=$HIVE_HOME/bin export HIVE_HOME 修改hive-default.xml 多個Hive節點的數據内容保存在HDFS上，通過配置文件，指向NameNode節點即可，例如： $ vim /opt/hive/conf/hive-default.xml &lt;property&gt;&lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;&lt;value&gt;hdfs://master:9000/user/hive/warehouse&lt;/value&gt;/user/hive/warehouse –&gt; &lt;description&gt;Master of default database for the warehouse&lt;/description&gt;&lt;/property&gt; 使用Hive的三種Metastore儲存方式 使用Derby資料庫儲存數據 使用本機的MySQL 使用遠端的MySQL 我自己熟悉的是MySQL當然就選他囉!! $ vim /opt/hive/conf/hive-site.xml &lt;configuration&gt;&lt;property&gt;&lt;name&gt;hive.metastore.local&lt;/name&gt;&lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;&lt;value&gt;jdbc:mysql://localhost:3306/hive?useUnicode=true&amp;characterEncoding=UTF-8&lt;/value&gt;&lt;description&gt;JDBC connect string for a JDBC metastore&lt;/description&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;&lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;&lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;&lt;value&gt;資料庫account&lt;/value&gt;&lt;description&gt;username to use against metastore database&lt;/description&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;&lt;value&gt;資料庫password&lt;/value&gt;&lt;description&gt;password to use against metastore database&lt;/description&gt;&lt;/property&gt;&lt;/configuration&gt; $ vim /opt/hive/conf/jpox.properties javax.jdo.PersistenceManagerFactoryClass=org.jpox.PersistenceManagerFactoryImpl org.jpox.autoCreateSchema=false org.jpox.validateTables=false org.jpox.validateColumns=false org.jpox.validateConstraints=false org.jpox.storeManagerType=rdbms org.jpox.autoCreateSchema=true org.jpox.autoStartMechanismMode=checked org.jpox.transactionIsolation=read_committed javax.jdo.option.DetachAllOnCommit=true javax.jdo.option.NontransactionalRead=true javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.ClientDriver javax.jdo.option.ConnectionURL=jdbc:derby://localhost:1527/metastore_db;create=true javax.jdo.option.ConnectionUserName=APP javax.jdo.option.ConnectionPassword=mine org.jpox.cache.level2=true org.jpox.cache.level2.type=SOFT 有一個需要注意的地方是，需要把一個jar包mysql-connector-java-5.1.15-bin.jar複製到hive的lib目錄下才行，否則執行語句的時候會出錯，範例如下： hive&gt; show tables; FAILED: Error in metadata: javax.jdo.JDOFatalInternalException: Error creating transactional connection factory NestedThrowables: java.lang.reflect.InvocationTargetException FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask 我當時安装MYSQL的时候是使用RPM来安装的，没找到mysql-connector-java-5.1.15-bin.jar。 在MySQL建立Hive資料庫並且設定語系 character_set_server = latin1 collation_server = latin1_swedish_ci default_character_set = latin1 讓Thrift使用Hive 修改/opt/hive/src/metastore/if/hive_metastore.thrift第6行，依實際路徑修改 include &quot;/opt/thrift/contrib/fb303/if/fb303.thrift&quot; 開始產生Thrift使用的Hive程式碼 $ mkdir /opt/thrift/packages/ $ cd /opt/thrift/packages/ Generate code並將目錄搬至packages $ thrift --gen php /opt/thrift/contrib/fb303/if/fb303.thrift $ cp -r gen-php/fb303 ./fb303 $ thrift --gen php -I include /opt/hive/src/metastore/if/hive_metastore.thrift $ cp -r gen-php/hive_metastore ./hive_metastore $ thrift --gen php -I include /opt/hive/src/service/if/hive_service.thrift $ cp -r gen-php/hive_service ./hive_service $ thrift --gen php -I include /opt/hive/src/ql/if/queryplan.thrift $ cp -r gen-php/queryplan ./queryplan 修改/opt/hive/src/metastore/if/hive_metastore.thrift第27行，依實際路徑修改 include &quot;/opt/hive/src/metastore/if/hive_metastore.thrift&quot; include &quot;/opt/hive/src/ql/if/queryplan.thrift&quot; 新增hive-thrift執行檔 $ vim /etc/init.d/hive-thrift #!/bin/bash # init script for Hive Thrift Interface. <a class="read-more" href="http://localhost:1313/post/hadoop/shi_yong_mapreduce_zhi_ti_dai_fang_an_hive/">&raquo;</a></p>
    </section>
    <footer class="post-meta">
        
        
            <img class="author-thumb" src="http://localhost:1313//images/517273.jpg" alt="Author image" nopin="nopin" />
        
        
            Alan
        
        on
            
                <a href="http://localhost:1313/tags/hadoop/">#hadoop</a>,
            
        
        <time class="post-date" datetime="2013-06-23T22:03:00Z">
            23 Jun 2013
        </time>
    </footer>
</article>

	
	   
<article class="post post">
    <header class="post-header">
        <h2 class="post-title"><a href="http://localhost:1313/post/hadoop/hadoop_gou_tong_qiao_liang_zhi_thrift_0__7/">Hadoop 溝通橋梁之 Thrift 0.7</a></h2>
    </header>
    <section class="post-excerpt">
        <p>會建置Thrift是因為我希望用PHP向Hadoop + Hbase 叢集環境溝通。Thrift是全世界第一大國Facebook釋出的開源項目之一，主要用來串接不同語言，讓他們之間能互相溝通。 這裡我就是用來讓PHP也能使用MapReduce和Hbase溝通的。在安裝的時候吃了不少苦頭阿&hellip;腦細胞死了不少。就算現在再架設一遍，我相信會再痛苦一次的。 檢查並安裝依賴的函式庫 $ yum search libboost libboost c++的函式庫 $ yum search yacc $ yum search flex make時會用到 $ yum search autoconf $ yum search automake automake 1.9以上actomake必須安裝2.6以上版本否則Compiler出錯。如果没有可自行編譯安装 $ yum search libtool $ yum search flex $ yum search bison $ yum search g++ $ yum search gcc-c++ $ yum search python-devel $ yum search libevent-devel $ yum search zlib-devel $ yum search ruby-devel $ yum install <a class="read-more" href="http://localhost:1313/post/hadoop/hadoop_gou_tong_qiao_liang_zhi_thrift_0__7/">&raquo;</a></p>
    </section>
    <footer class="post-meta">
        
        
            <img class="author-thumb" src="http://localhost:1313//images/517273.jpg" alt="Author image" nopin="nopin" />
        
        
            Alan
        
        on
            
                <a href="http://localhost:1313/tags/hadoop/">#hadoop</a>,
            
        
        <time class="post-date" datetime="2013-06-18T11:57:00Z">
            18 Jun 2013
        </time>
    </footer>
</article>

	
	   
<article class="post post">
    <header class="post-header">
        <h2 class="post-title"><a href="http://localhost:1313/post/hadoop/hadoop_&#43;_hbase_cong_ji_huan_jing/">Hadoop &#43; Hbase 叢集環境</a></h2>
    </header>
    <section class="post-excerpt">
        <p>這是配合著CentOS 5.5 + Hadoop 0.20以及CentOS 5.5 + Hbase 0.94.8建立的叢集系統，為了方便記錄，所以我分開介紹囉。但記錄畢竟有點久了，有些步驟還需要再架一次才會更正確。 因為Hadoop本身的優勢將文件的儲存和任務處理分散化，Hadoop分散式架構中有兩種負責不同功能的服務器Master服務器和Slave服務器，安裝時假設要為2台服務器安裝Hadoop架構。 本篇環境介紹 安裝了Java 1.6.x,或以後的版本 兩台服務器名稱為master和slave 兩台服務器操作系統均為centos5.*且版本大於等於5.4 master將作為master主服務器使用，slave將作為slave服務器使用: master和slave的wget命令均可正常使用 master和slave均正常運行且可正確聯繫 master和slave空間足夠 master和slave均已獲取root權限 master的ip位址為192.168.1.28，slave的ip位址為192.168.1.29 設置環境變數 設置hosts在Master和slave的/etc/hosts下共同增加 $ vim /etc/hosts 192.168.1.28 master 192.168.1.29 slave 修改master的hostname文件 $ vim /etc/hostname master 修改slave的hostname文件 $ vim /etc/hostname slave 免密碼登入遠端電腦 請參考SSH免密碼登入遠端電腦 重新配置Hadoop 配置core-site.xml，在節點下添加 $ vim /opt/hadoop/conf/core-site.xml &lt;property&gt;&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;&lt;value&gt;/home/hadoop-${user.name}&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;fs.default.name&lt;/name&gt;&lt;value&gt;hdfs://master:9000&lt;/value&gt;&lt;/property&gt; 配置mapred-site.xml，在節點下添加 $ vim /opt/hadoop/conf/mapred-site.xml &lt;property&gt;&lt;name&gt;mapred.job.tracker&lt;/name&gt;&lt;value&gt;master:9001&lt;/value&gt;&lt;/property&gt; 修改master文件 $ vim /opt/hadoop/conf/master master 修改slaves $ vim /opt/hadoop/conf/slaves slave 修改内容，注意不是添加是更改 重新配置Hbase 配置hbase-env.sh $ vim /opt/hbase/conf/hbase-env.sh export JAVA_HOME=/usr/lib/jvm/java-6-sun export HADOOP_CONF_DIR=/opt/hadoop/conf export HBASE_HOME=/opt/hbase export HBASE_LOG_DIR=/var/hadoop/hbase-logs export HBASE_PID_DIR=/var/hadoop/hbase-pids export HBASE_MANAGES_ZK=true export HBASE_CLASSPATH=$HBASE_CLASSPATH:/opt/hadoop/conf 配置hbase-site.xml，在節點下添加 $ vim /opt/hbase/conf/hbase-site.xml &lt;configuration&gt;&lt;property&gt;&lt;name&gt;hbase.rootdir&lt;/name&gt;&lt;value&gt;hdfs://master:9000/hbase&lt;/value&gt;&lt;description&gt;The directory shared by region servers. <a class="read-more" href="http://localhost:1313/post/hadoop/hadoop_&#43;_hbase_cong_ji_huan_jing/">&raquo;</a></p>
    </section>
    <footer class="post-meta">
        
        
            <img class="author-thumb" src="http://localhost:1313//images/517273.jpg" alt="Author image" nopin="nopin" />
        
        
            Alan
        
        on
            
                <a href="http://localhost:1313/tags/hadoop/">#hadoop</a>,
            
        
        <time class="post-date" datetime="2013-06-17T14:32:00Z">
            17 Jun 2013
        </time>
    </footer>
</article>

	
	   
<article class="post post">
    <header class="post-header">
        <h2 class="post-title"><a href="http://localhost:1313/post/hadoop/centos_55_&#43;_hbase_0948/">CentOS 5.5 &#43; Hbase 0.94.8</a></h2>
    </header>
    <section class="post-excerpt">
        <p>本篇與CentOS 5.5 + Hadoop 0.20其實是同一時期的，Hbase有別於RDBMS資料庫，底層是使用了分散式的檔案系統(Hadoop HDFS)，他把不同的表拆成很多份，由不同的伺服器各自負責存取部分的資料，藉由這樣達到分散式架構，提高效能。詳細功能官網都有說明喔! 本篇預設環境： 已經安裝了Java 1.6.x,或以後的版本 hosts改為slave 建立Hbase 一樣為Hbase找個家吧，從官網下載下來。 $ cd /opt $ wget 'http://apache.cdpa.nsysu.edu.tw/hbase/stable/hbase-0.94.8.tar.gz' $ mv hbase-0.94.8 hbase $ mkdir -p /usr/local/hbase $ chown -R $USER:$USER /opt/hbase 進入conf配置hbse-env.sh $ vim /opt/hbase/conf/hbase-env.sh export HBASE_HOME=/opt/hbase export JAVA_HOME=/usr/java/jdk1.x.x_xx export HBASE_MANAGES_ZK=true #用Hbase的zookeeper 進入conf配置regionservers替换其中内容 $ vim /opt/hbase/conf/regionservers slave 進入conf配置hbase-site.xml $ vim /opt/hbase/conf/hbase-site.xml &lt;configuration&gt;&lt;property&gt;&lt;name&gt;hbase.rootdir&lt;/name&gt;&lt;value&gt;hdfs://slave:9000/hbase&lt;/value&gt;&lt;description&gt;The directory shared by region servers.&lt;/description&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;hbase.tmp.dir&lt;/name&gt;&lt;value&gt;/var/hadoop/hbase-${user.name}&lt;/value&gt;&lt;description&gt;Temporary directory on the local filesystem.&lt;/description&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;hbase.cluster.distributed&lt;/name&gt;&lt;value&gt;true&lt;/value&gt;&lt;description&gt;The mode the cluster will be in. Possible values are false: standalone and pseudo-distributed setups with managed Zookeeper true: fully-distributed with unmanaged Zookeeper Quorum (see hbase-env.sh)&lt;/description&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt;&lt;value&gt;2222&lt;/value&gt;&lt;description&gt;Property from ZooKeeper's config zoo.cfg.&lt;/description&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;&lt;value&gt;slave&lt;/value&gt;&lt;description&gt;Comma separated list of servers in the ZooKeeper Quorum.&lt;/description&gt;&lt;/property&gt;&lt;/configuration&gt; 這樣就配置完成了，接下來就啟動Hbase吧 $ /opt/hbase/bin/start-hbase.sh root@localhost's password: localhost: starting zookeeper, logging to /usr/local/hbase/bin/../logs/hbase-root-zookeeper-localhost.localdomain.out starting master, logging to /usr/local/hbase/logs/hbase-root- ...以下省略 檢查啟動狀況 $ ps aux | grep hbase root 24578 3.0 2.7 1191892 28504 ? <a class="read-more" href="http://localhost:1313/post/hadoop/centos_55_&#43;_hbase_0948/">&raquo;</a></p>
    </section>
    <footer class="post-meta">
        
        
            <img class="author-thumb" src="http://localhost:1313//images/517273.jpg" alt="Author image" nopin="nopin" />
        
        
            Alan
        
        on
            
                <a href="http://localhost:1313/tags/hadoop/">#hadoop</a>,
            
        
        <time class="post-date" datetime="2013-06-15T23:57:00Z">
            15 Jun 2013
        </time>
    </footer>
</article>

	
	   
<article class="post post">
    <header class="post-header">
        <h2 class="post-title"><a href="http://localhost:1313/post/hadoop/centos_55_&#43;_hadoop_020/">CentOS 5.5 &#43; Hadoop 0.20</a></h2>
    </header>
    <section class="post-excerpt">
        <p>緊接著再來一發舊的，這一篇已經是去年的記錄了，當時是因為公司想要導入Hadoop分析使用者行為，所以我才開始著手研究，就趁這個時候把他整理一下吧，現在的版本都已經不知道升到多少去了。 建立Hadoop基本環境 下載Java JDK並開始安裝，設置Java使用環境必須要1.6以上，並且重新載入。 $ ./jdk-7u21-linux-i586.rpm find / -name java /usr/java/jdk1.x.x-xx $ ln -s /usr/java/jdk1.x.x-xx /usr/java/jdk $ vim ~/.bashrc export JAVA_HOME=/usr/java/jdk export CLASSPATH=$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH:$HOME/bin export HADOOP_HOME=/opt/hadoop $ source ~/.bashrc 建立hadoop帳號，設定SSH，切換為 hadoop 身分，或直接使用root $ yum -y install openssh $ su hadoop $ passwd hadoop $ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa Generating public/private dsa key pair. Enter file in which to save the key (/home/ hadoop/.ssh/id_dsa): Enter passphrase (empty for no passphrase): &gt; ~/.ssh/authorized_keys $ chmod 600 .ssh/authorized_keys $ ssh hadoop@localhost 找一個讓Hadoop安身立命的好地方，這邊我是放在opt底下，下載後解壓縮 $ cd /opt $ wget 'http://apache.ntu.edu.tw/hadoop/core/hadoop-0.20.2/hadoop-0.20.2.tar.gz' $ tar xzvf hadoop-0.20.2.tar.gz $ mv hadoop-0.20.2 hadoop 設置hadoop-env.sh在文件最末端加上 $ vim /opt/hadoop/conf/hadoop-env.sh export JAVA_HOME=/usr/java/jdk1.x.x-xx 測試一下hadoop可否執行 $ /opt/hadoop/bin/hadoop Usage: hadoop [--config confdir] COMMAND where COMMAND is one of: ...以下省略 測試 Local (Standalone) Mode，此模式下每個 Hadoop daemon 執行在一個分離的 Java 程序中。 $ mkdir /opt/hadoop/input $ cp /opt/hadoop/conf/*.xml input $ bin/hadoop jar hadoop-*-examples.jar grep input output 'dfs[a-z.]+' 10/02/22 10:47:42 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName 以下省略 $ cat /opt/hadoop/output/* 1 dfsadmin 更改config檔 $ vim /opt/hadoop/conf/core-site.xml &lt;configuration&gt;&lt;property&gt;&lt;name&gt;fs.default.name&lt;/name&gt;&lt;value&gt;hdfs://localhost:9000&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; $ vim /opt/hadoop/conf/hdfs-site.xml &lt;configuration&gt;&lt;property&gt;&lt;name&gt;dfs.replication&lt;/name&gt;&lt;value&gt;1&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; $ vim /opt/hadoop/conf/mapred-site.xml &lt;configuration&gt;&lt;property&gt;&lt;name&gt;mapred.job.tracker&lt;/name&gt;&lt;value&gt;localhost:9001&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; 格式化分散式檔案系統 $ /opt/hadoop/bin/hadoop namenode -format 10/02/22 11:02:36 INFO namenode.NameNode: STARTUP_MSG: /************************************************************ ...以下省略 啟動 hadoop daemons $ /opt/hadoop/bin/start-all.sh namenode running as process 17390. <a class="read-more" href="http://localhost:1313/post/hadoop/centos_55_&#43;_hadoop_020/">&raquo;</a></p>
    </section>
    <footer class="post-meta">
        
        
            <img class="author-thumb" src="http://localhost:1313//images/517273.jpg" alt="Author image" nopin="nopin" />
        
        
            Alan
        
        on
            
                <a href="http://localhost:1313/tags/hadoop/">#hadoop</a>,
            
        
        <time class="post-date" datetime="2013-06-13T23:12:00Z">
            13 Jun 2013
        </time>
    </footer>
</article>

	

	<nav class="pagination" role="navigation">
	
	<span class="page-number">Page 1 of 1</span>
	
</nav>

</main>



    <footer class="site-footer clearfix">
        <section class="copyright"><a href="">Hello World!!</a> &copy; Copyright Alan - 2016</section>
        
        <section class="poweredby">Proudly generated by <a class="icon-hugo" href="http://gohugo.io">HUGO</a>, with <a class="icon-theme" href="https://github.com/vjeantet/hugo-theme-casper">Casper</a> theme</section>
        
    </footer>
    </div>
    <script type="text/javascript" src="http://localhost:1313/js/jquery.js"></script>
    <script type="text/javascript" src="http://localhost:1313/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="http://localhost:1313/js/index.js"></script>
    
</body>
</html>
