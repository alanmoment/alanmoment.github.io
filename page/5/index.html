<!DOCTYPE html>
<html lang="en">
<head prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# website: http://ogp.me/ns/website#">
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
    <meta name="description" content="">
    <meta property="og:title" content="Hello World!!">
    
    <meta property="og:type" content="website">
    
    <meta property="og:description" content="">
    <meta property="og:url" content="http://alanmoment.github.io/">
    <meta property="og:site_name" content="Hello World!!">
    
    <meta name="generator" content="Hugo 0.15" />
    <title>Hello World!! &middot; Hello World!!</title>
    
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.3.0/css/font-awesome.min.css">
    
    <link rel="stylesheet" href="http://alanmoment.github.io/css/style.css">
    <link href="http://alanmoment.github.io/index.xml" rel="alternate" type="application/rss+xml" title="Hello World!!" />

    
    
</head>
<body>
<nav class="navbar navbar-default navbar-fixed-top visible-xs">
	<div class="container-fluid">
		<div class="navbar-header">
			<button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
				<span class="sr-only">Toggle navigation</span>
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
			</button>
			
				<a class="navbar-brand" href="http://alanmoment.github.io/">Hello World!!</a>
			
		</div>
		<div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
			<ul class="nav navbar-nav">
				
				
					<li><a href="http://alanmoment.github.io//">Home</a></li>
				
					<li><a href="http://alanmoment.github.io/page/about/">About</a></li>
				
			</ul>
		</div>
	</div>
</nav>
<div class="container-fluid">
	<div class="row">
		<div id="menu" class="hidden-xs col-sm-4 col-md-3">
	<div id="menu-content" class="vertical-align">
		
			<h1 class="text-center"><a href="http://alanmoment.github.io/">Hello World!!</a></h1>
		
		
		
			<small class="text-center center-block">you can do anything you want to do.</small>
		
		
		
			<img id="profile-pic" src="http://alanmoment.github.io///images/avatar.jpg" alt="My Picture" class="img-circle center-block">
		
		<div id="social" class="text-center">
			<a href="https://twitter.com/alanmoment"><i class="fa fa-twitter fa-2x"></i></a>
			<a href="https://www.linkedin.com/in/alanmoment"><i class="fa fa-linkedin fa-2x"></i></a>
			<a href="https://github.com/alanmoment"><i class="fa fa-github fa-2x"></i></a>
			<a href="mailto:alan.moment77@gmail.com"><i class="fa fa-envelope-o fa-2x"></i></a>
		</div>
		<div id="links" class="text-center">
			
			
				<a href="http://alanmoment.github.io//">Home</a>
			
				<a href="http://alanmoment.github.io/page/about/">About</a>
			
		</div>
	</div>
</div>
		<div id="content" class="col-xs-12 col-sm-8 col-md-9">
			<div class="row">
				<div id="post" class="col-sm-offset-1 col-sm-10 col-md-10 col-lg-8">

<header>
	<h1>What I'm Thinking</h1>
</header>


	<div class="panel panel-default">
	<div class="panel-header">
		<h3>
			<a href="http://alanmoment.github.io/post/hadoop/shi_yong_mapreduce_zhi_ti_dai_fang_an_hive/">使用MapReduce之替代方案Hive</a>
			<br>
			<small>
				23 June 2013
			</small>
		</h3>
	</div>
	<div class="panel-body">
		若要操作Hadoop就必須要會MapReduce，很好!!在Hadoop很夯之前相信很多人都對MapReduce非常陌生，沒錯!!那真的是有點困難，但是呢，若我講SQL語言，相信你一定信心十足吧!! 因此囉，Facebook當初也了這個問題傷透了腦筋，因為要找一個熟悉MapReduce的工程師比找一個會SQL語法的工程師還困難的情況底下，他們想出了應變之道，那就是用極接近SQL語言的方式去操作MapReduce，因為找到會SQL語言的人較容易。 所以Hive就是為此誕生的，這是Facebook一個部門的研發成果，後來為了讓更多人可以應用，他們將其釋出提供給Apache當作開源項目，讓Hive開始發揚光大，更多的介紹官網都有唷。 若你看不順眼Hive，你也可以選擇其他的諸如PIG(我不是在罵人&hellip;真的叫PIG)，或是你真的想挑戰MapReduce當然也可以，任君挑選。因為我喜歡Hive的Logo所以囉，我就選他了。 建立Hive 從官網下載或是 $ cd /opt $ wget 'http://ftp.stut.edu.tw/var/ftp/pub/OpenSource/apache//hive/hive-0.7.1/hive-0.7.1.tar.gz' $ mv hive-0.7.1 /opt/hive 安裝ivy $ cd /tmp $ wget 'http://www.apache.org/dist/ant/ivy/2.3.0/apache-ivy-2.3.0-bin-with-deps.tar.gz' $ tar zxvf apache-ivy-2.3.0-bin-with-deps.tar.gz $ mv apache-ivy-2.3.0 /usr/local $ ln -s apache-ivy-2.3.0 ivy 配置環境 $ vim ~/.bashrc export HIVE_HOME=/opt/hive export IVY_HOME=/usr/local/ivy export PATH=$HIVE_HOME/bin export HIVE_HOME 修改hive-default.xml 多個Hive節點的數據内容保存在HDFS上，通過配置文件，指向NameNode節點即可，例如： $ vim /opt/hive/conf/hive-default.xml &lt;property&gt;&lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;&lt;value&gt;hdfs://master:9000/user/hive/warehouse&lt;/value&gt;/user/hive/warehouse –&gt; &lt;description&gt;Master of default database for the warehouse&lt;/description&gt;&lt;/property&gt; 使用Hive的三種Metastore儲存方式 使用Derby資料庫儲存數據 使用本機的MySQL 使用遠端的MySQL 我自己熟悉的是MySQL當然就選他囉!! $ vim /opt/hive/conf/hive-site.xml &lt;configuration&gt;&lt;property&gt;&lt;name&gt;hive.metastore.local&lt;/name&gt;&lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;&lt;value&gt;jdbc:mysql://localhost:3306/hive?useUnicode=true&amp;characterEncoding=UTF-8&lt;/value&gt;&lt;description&gt;JDBC connect string for a JDBC metastore&lt;/description&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;&lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;&lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;&lt;value&gt;資料庫account&lt;/value&gt;&lt;description&gt;username to use against metastore database&lt;/description&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;&lt;value&gt;資料庫password&lt;/value&gt;&lt;description&gt;password to use against metastore database&lt;/description&gt;&lt;/property&gt;&lt;/configuration&gt; $ vim /opt/hive/conf/jpox.properties javax.jdo.PersistenceManagerFactoryClass=org.jpox.PersistenceManagerFactoryImpl org.jpox.autoCreateSchema=false org.jpox.validateTables=false org.jpox.validateColumns=false org.jpox.validateConstraints=false org.jpox.storeManagerType=rdbms org.jpox.autoCreateSchema=true org.jpox.autoStartMechanismMode=checked org.jpox.transactionIsolation=read_committed javax.jdo.option.DetachAllOnCommit=true javax.jdo.option.NontransactionalRead=true javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.ClientDriver javax.jdo.option.ConnectionURL=jdbc:derby://localhost:1527/metastore_db;create=true javax.jdo.option.ConnectionUserName=APP javax.jdo.option.ConnectionPassword=mine org.jpox.cache.level2=true org.jpox.cache.level2.type=SOFT 有一個需要注意的地方是，需要把一個jar包mysql-connector-java-5.1.15-bin.jar複製到hive的lib目錄下才行，否則執行語句的時候會出錯，範例如下： hive&gt; show tables; FAILED: Error in metadata: javax.jdo.JDOFatalInternalException: Error creating transactional connection factory NestedThrowables: java.lang.reflect.InvocationTargetException FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask 我當時安装MYSQL的时候是使用RPM来安装的，没找到mysql-connector-java-5.1.15-bin.jar。 在MySQL建立Hive資料庫並且設定語系 character_set_server = latin1 collation_server = latin1_swedish_ci default_character_set = latin1 讓Thrift使用Hive 修改/opt/hive/src/metastore/if/hive_metastore.thrift第6行，依實際路徑修改 include &quot;/opt/thrift/contrib/fb303/if/fb303.thrift&quot; 開始產生Thrift使用的Hive程式碼 $ mkdir /opt/thrift/packages/ $ cd /opt/thrift/packages/ Generate code並將目錄搬至packages $ thrift --gen php /opt/thrift/contrib/fb303/if/fb303.thrift $ cp -r gen-php/fb303 ./fb303 $ thrift --gen php -I include /opt/hive/src/metastore/if/hive_metastore.thrift $ cp -r gen-php/hive_metastore ./hive_metastore $ thrift --gen php -I include /opt/hive/src/service/if/hive_service.thrift $ cp -r gen-php/hive_service ./hive_service $ thrift --gen php -I include /opt/hive/src/ql/if/queryplan.thrift $ cp -r gen-php/queryplan ./queryplan 修改/opt/hive/src/metastore/if/hive_metastore.thrift第27行，依實際路徑修改 include &quot;/opt/hive/src/metastore/if/hive_metastore.thrift&quot; include &quot;/opt/hive/src/ql/if/queryplan.thrift&quot; 新增hive-thrift執行檔 $ vim /etc/init.d/hive-thrift #!/bin/bash # init script for Hive Thrift Interface.
		
			... <a href="http://alanmoment.github.io/post/hadoop/shi_yong_mapreduce_zhi_ti_dai_fang_an_hive/">Read More</a>
		
	</div>
	<div class="panel-footer">
		
		<small class="text-muted">
			
			
				<a href="http://alanmoment.github.io/tags/hadoop"><span class="label label-success">hadoop</span></a>
			
		</small>
		
	</div>
</div>


	<div class="panel panel-default">
	<div class="panel-header">
		<h3>
			<a href="http://alanmoment.github.io/post/hadoop/hadoop_gou_tong_qiao_liang_zhi_thrift_0__7/">Hadoop 溝通橋梁之 Thrift 0.7</a>
			<br>
			<small>
				18 June 2013
			</small>
		</h3>
	</div>
	<div class="panel-body">
		會建置Thrift是因為我希望用PHP向Hadoop + Hbase 叢集環境溝通。Thrift是全世界第一大國Facebook釋出的開源項目之一，主要用來串接不同語言，讓他們之間能互相溝通。 這裡我就是用來讓PHP也能使用MapReduce和Hbase溝通的。在安裝的時候吃了不少苦頭阿&hellip;腦細胞死了不少。就算現在再架設一遍，我相信會再痛苦一次的。 檢查並安裝依賴的函式庫 $ yum search libboost libboost c++的函式庫 $ yum search yacc $ yum search flex make時會用到 $ yum search autoconf $ yum search automake automake 1.9以上actomake必須安裝2.6以上版本否則Compiler出錯。如果没有可自行編譯安装 $ yum search libtool $ yum search flex $ yum search bison $ yum search g++ $ yum search gcc-c++ $ yum search python-devel $ yum search libevent-devel $ yum search zlib-devel $ yum search ruby-devel $ yum install
		
			... <a href="http://alanmoment.github.io/post/hadoop/hadoop_gou_tong_qiao_liang_zhi_thrift_0__7/">Read More</a>
		
	</div>
	<div class="panel-footer">
		
		<small class="text-muted">
			
			
				<a href="http://alanmoment.github.io/tags/hadoop"><span class="label label-success">hadoop</span></a>
			
		</small>
		
	</div>
</div>


	<div class="panel panel-default">
	<div class="panel-header">
		<h3>
			<a href="http://alanmoment.github.io/post/hadoop/hadoop_&#43;_hbase_cong_ji_huan_jing/">Hadoop &#43; Hbase 叢集環境</a>
			<br>
			<small>
				17 June 2013
			</small>
		</h3>
	</div>
	<div class="panel-body">
		這是配合著CentOS 5.5 + Hadoop 0.20以及CentOS 5.5 + Hbase 0.94.8建立的叢集系統，為了方便記錄，所以我分開介紹囉。但記錄畢竟有點久了，有些步驟還需要再架一次才會更正確。 因為Hadoop本身的優勢將文件的儲存和任務處理分散化，Hadoop分散式架構中有兩種負責不同功能的服務器Master服務器和Slave服務器，安裝時假設要為2台服務器安裝Hadoop架構。 本篇環境介紹 安裝了Java 1.6.x,或以後的版本 兩台服務器名稱為master和slave 兩台服務器操作系統均為centos5.*且版本大於等於5.4 master將作為master主服務器使用，slave將作為slave服務器使用: master和slave的wget命令均可正常使用 master和slave均正常運行且可正確聯繫 master和slave空間足夠 master和slave均已獲取root權限 master的ip位址為192.168.1.28，slave的ip位址為192.168.1.29 設置環境變數 設置hosts在Master和slave的/etc/hosts下共同增加 $ vim /etc/hosts 192.168.1.28 master 192.168.1.29 slave 修改master的hostname文件 $ vim /etc/hostname master 修改slave的hostname文件 $ vim /etc/hostname slave 免密碼登入遠端電腦 請參考SSH免密碼登入遠端電腦 重新配置Hadoop 配置core-site.xml，在節點下添加 $ vim /opt/hadoop/conf/core-site.xml &lt;property&gt;&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;&lt;value&gt;/home/hadoop-${user.name}&lt;/value&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;fs.default.name&lt;/name&gt;&lt;value&gt;hdfs://master:9000&lt;/value&gt;&lt;/property&gt; 配置mapred-site.xml，在節點下添加 $ vim /opt/hadoop/conf/mapred-site.xml &lt;property&gt;&lt;name&gt;mapred.job.tracker&lt;/name&gt;&lt;value&gt;master:9001&lt;/value&gt;&lt;/property&gt; 修改master文件 $ vim /opt/hadoop/conf/master master 修改slaves $ vim /opt/hadoop/conf/slaves slave 修改内容，注意不是添加是更改 重新配置Hbase 配置hbase-env.sh $ vim /opt/hbase/conf/hbase-env.sh export JAVA_HOME=/usr/lib/jvm/java-6-sun export HADOOP_CONF_DIR=/opt/hadoop/conf export HBASE_HOME=/opt/hbase export HBASE_LOG_DIR=/var/hadoop/hbase-logs export HBASE_PID_DIR=/var/hadoop/hbase-pids export HBASE_MANAGES_ZK=true export HBASE_CLASSPATH=$HBASE_CLASSPATH:/opt/hadoop/conf 配置hbase-site.xml，在節點下添加 $ vim /opt/hbase/conf/hbase-site.xml &lt;configuration&gt;&lt;property&gt;&lt;name&gt;hbase.rootdir&lt;/name&gt;&lt;value&gt;hdfs://master:9000/hbase&lt;/value&gt;&lt;description&gt;The directory shared by region servers.
		
			... <a href="http://alanmoment.github.io/post/hadoop/hadoop_&#43;_hbase_cong_ji_huan_jing/">Read More</a>
		
	</div>
	<div class="panel-footer">
		
		<small class="text-muted">
			
			
				<a href="http://alanmoment.github.io/tags/hadoop"><span class="label label-success">hadoop</span></a>
			
		</small>
		
	</div>
</div>


	<div class="panel panel-default">
	<div class="panel-header">
		<h3>
			<a href="http://alanmoment.github.io/post/os/linux/sshmian_mi_ma_deng_ru_yuan_duan_dian_nao/">SSH免密碼登入遠端電腦</a>
			<br>
			<small>
				16 June 2013
			</small>
		</h3>
	</div>
	<div class="panel-body">
		YUM安裝SSH $ yum -y install openssh 用ssh-keygen做出公用和私有鑰匙，並且設置無密碼連接，把master的id_rsa.pub傳給slave $ ssh-keygen -t rsa -C root Generating public/private dsa key pair. Enter file in which to save the key (/home/root/.ssh/id_rsa): Enter passphrase (empty for no passphrase): &gt; /root/.ssh/authorized_keys $ exit 再登入一次slave $ ssh 192.168.1.29 已經不用再輸入密碼囉，這樣就完成了。 2014/1/15 9:37 pm 將id_dsa修正為id_rsa
		
	</div>
	<div class="panel-footer">
		
		<small class="text-muted">
			
			
				<a href="http://alanmoment.github.io/tags/linux"><span class="label label-success">linux</span></a>
			
				<a href="http://alanmoment.github.io/tags/ssh"><span class="label label-success">ssh</span></a>
			
		</small>
		
	</div>
</div>


	<div class="panel panel-default">
	<div class="panel-header">
		<h3>
			<a href="http://alanmoment.github.io/post/hadoop/centos_55_&#43;_hbase_0948/">CentOS 5.5 &#43; Hbase 0.94.8</a>
			<br>
			<small>
				15 June 2013
			</small>
		</h3>
	</div>
	<div class="panel-body">
		本篇與CentOS 5.5 + Hadoop 0.20其實是同一時期的，Hbase有別於RDBMS資料庫，底層是使用了分散式的檔案系統(Hadoop HDFS)，他把不同的表拆成很多份，由不同的伺服器各自負責存取部分的資料，藉由這樣達到分散式架構，提高效能。詳細功能官網都有說明喔! 本篇預設環境： 已經安裝了Java 1.6.x,或以後的版本 hosts改為slave 建立Hbase 一樣為Hbase找個家吧，從官網下載下來。 $ cd /opt $ wget 'http://apache.cdpa.nsysu.edu.tw/hbase/stable/hbase-0.94.8.tar.gz' $ mv hbase-0.94.8 hbase $ mkdir -p /usr/local/hbase $ chown -R $USER:$USER /opt/hbase 進入conf配置hbse-env.sh $ vim /opt/hbase/conf/hbase-env.sh export HBASE_HOME=/opt/hbase export JAVA_HOME=/usr/java/jdk1.x.x_xx export HBASE_MANAGES_ZK=true #用Hbase的zookeeper 進入conf配置regionservers替换其中内容 $ vim /opt/hbase/conf/regionservers slave 進入conf配置hbase-site.xml $ vim /opt/hbase/conf/hbase-site.xml &lt;configuration&gt;&lt;property&gt;&lt;name&gt;hbase.rootdir&lt;/name&gt;&lt;value&gt;hdfs://slave:9000/hbase&lt;/value&gt;&lt;description&gt;The directory shared by region servers.&lt;/description&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;hbase.tmp.dir&lt;/name&gt;&lt;value&gt;/var/hadoop/hbase-${user.name}&lt;/value&gt;&lt;description&gt;Temporary directory on the local filesystem.&lt;/description&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;hbase.cluster.distributed&lt;/name&gt;&lt;value&gt;true&lt;/value&gt;&lt;description&gt;The mode the cluster will be in. Possible values are false: standalone and pseudo-distributed setups with managed Zookeeper true: fully-distributed with unmanaged Zookeeper Quorum (see hbase-env.sh)&lt;/description&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt;&lt;value&gt;2222&lt;/value&gt;&lt;description&gt;Property from ZooKeeper's config zoo.cfg.&lt;/description&gt;&lt;/property&gt;&lt;property&gt;&lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;&lt;value&gt;slave&lt;/value&gt;&lt;description&gt;Comma separated list of servers in the ZooKeeper Quorum.&lt;/description&gt;&lt;/property&gt;&lt;/configuration&gt; 這樣就配置完成了，接下來就啟動Hbase吧 $ /opt/hbase/bin/start-hbase.sh root@localhost's password: localhost: starting zookeeper, logging to /usr/local/hbase/bin/../logs/hbase-root-zookeeper-localhost.localdomain.out starting master, logging to /usr/local/hbase/logs/hbase-root- ...以下省略 檢查啟動狀況 $ ps aux | grep hbase root 24578 3.0 2.7 1191892 28504 ?
		
			... <a href="http://alanmoment.github.io/post/hadoop/centos_55_&#43;_hbase_0948/">Read More</a>
		
	</div>
	<div class="panel-footer">
		
		<small class="text-muted">
			
			
				<a href="http://alanmoment.github.io/tags/hadoop"><span class="label label-success">hadoop</span></a>
			
		</small>
		
	</div>
</div>


	<div class="panel panel-default">
	<div class="panel-header">
		<h3>
			<a href="http://alanmoment.github.io/post/hadoop/centos_55_&#43;_hadoop_020/">CentOS 5.5 &#43; Hadoop 0.20</a>
			<br>
			<small>
				13 June 2013
			</small>
		</h3>
	</div>
	<div class="panel-body">
		緊接著再來一發舊的，這一篇已經是去年的記錄了，當時是因為公司想要導入Hadoop分析使用者行為，所以我才開始著手研究，就趁這個時候把他整理一下吧，現在的版本都已經不知道升到多少去了。 建立Hadoop基本環境 下載Java JDK並開始安裝，設置Java使用環境必須要1.6以上，並且重新載入。 $ ./jdk-7u21-linux-i586.rpm find / -name java /usr/java/jdk1.x.x-xx $ ln -s /usr/java/jdk1.x.x-xx /usr/java/jdk $ vim ~/.bashrc export JAVA_HOME=/usr/java/jdk export CLASSPATH=$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH:$HOME/bin export HADOOP_HOME=/opt/hadoop $ source ~/.bashrc 建立hadoop帳號，設定SSH，切換為 hadoop 身分，或直接使用root $ yum -y install openssh $ su hadoop $ passwd hadoop $ ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa Generating public/private dsa key pair. Enter file in which to save the key (/home/ hadoop/.ssh/id_dsa): Enter passphrase (empty for no passphrase): &gt; ~/.ssh/authorized_keys $ chmod 600 .ssh/authorized_keys $ ssh hadoop@localhost 找一個讓Hadoop安身立命的好地方，這邊我是放在opt底下，下載後解壓縮 $ cd /opt $ wget 'http://apache.ntu.edu.tw/hadoop/core/hadoop-0.20.2/hadoop-0.20.2.tar.gz' $ tar xzvf hadoop-0.20.2.tar.gz $ mv hadoop-0.20.2 hadoop 設置hadoop-env.sh在文件最末端加上 $ vim /opt/hadoop/conf/hadoop-env.sh export JAVA_HOME=/usr/java/jdk1.x.x-xx 測試一下hadoop可否執行 $ /opt/hadoop/bin/hadoop Usage: hadoop [--config confdir] COMMAND where COMMAND is one of: ...以下省略 測試 Local (Standalone) Mode，此模式下每個 Hadoop daemon 執行在一個分離的 Java 程序中。 $ mkdir /opt/hadoop/input $ cp /opt/hadoop/conf/*.xml input $ bin/hadoop jar hadoop-*-examples.jar grep input output 'dfs[a-z.]+' 10/02/22 10:47:42 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName 以下省略 $ cat /opt/hadoop/output/* 1 dfsadmin 更改config檔 $ vim /opt/hadoop/conf/core-site.xml &lt;configuration&gt;&lt;property&gt;&lt;name&gt;fs.default.name&lt;/name&gt;&lt;value&gt;hdfs://localhost:9000&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; $ vim /opt/hadoop/conf/hdfs-site.xml &lt;configuration&gt;&lt;property&gt;&lt;name&gt;dfs.replication&lt;/name&gt;&lt;value&gt;1&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; $ vim /opt/hadoop/conf/mapred-site.xml &lt;configuration&gt;&lt;property&gt;&lt;name&gt;mapred.job.tracker&lt;/name&gt;&lt;value&gt;localhost:9001&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; 格式化分散式檔案系統 $ /opt/hadoop/bin/hadoop namenode -format 10/02/22 11:02:36 INFO namenode.NameNode: STARTUP_MSG: /************************************************************ ...以下省略 啟動 hadoop daemons $ /opt/hadoop/bin/start-all.sh namenode running as process 17390.
		
			... <a href="http://alanmoment.github.io/post/hadoop/centos_55_&#43;_hadoop_020/">Read More</a>
		
	</div>
	<div class="panel-footer">
		
		<small class="text-muted">
			
			
				<a href="http://alanmoment.github.io/tags/hadoop"><span class="label label-success">hadoop</span></a>
			
		</small>
		
	</div>
</div>


	<div class="panel panel-default">
	<div class="panel-header">
		<h3>
			<a href="http://alanmoment.github.io/post/other/qing_zhu_octopress_kai_zhang/">慶祝Octopress開張</a>
			<br>
			<small>
				12 June 2013
			</small>
		</h3>
	</div>
	<div class="panel-body">
		搞了老半天終於搞定，來試試看好不好用!!! 立馬來一篇教學文。Github + Octopress 安裝 RVM Installing RVM這邊有非常完整的教學。 建立Octopress 找一個讓程式碼安身的地方，我習慣放在home。(好吧這是來亂的) $ mkdir /home/ruby 接著就是到Github 登入或註冊帳號，並且開一個新的Repositories，以我為範例就是 alanmoment.github.com，然後就是Ctrl+C 、Ctrl+V的快樂時光。 $ rvm install 1.9.2 &amp;&amp; rvm use 1.9.2 $ git clone git://github.com/imathis/octopress.git octopress Initialized empty Git repository in /home/ruby/octopress/.git/ remote: Counting objects: 10296, done. remote: Compressing objects: 100% (4511/4511), done. remote: Total 10296 (delta 5628), reused 9415 (delta 4937) Receiving objects: 100% (10296/10296), 2.28 MiB | 1.01 MiB/s, done. Resolving deltas: 100% (5628/5628), done.
		
			... <a href="http://alanmoment.github.io/post/other/qing_zhu_octopress_kai_zhang/">Read More</a>
		
	</div>
	<div class="panel-footer">
		
		<small class="text-muted">
			
			
				<a href="http://alanmoment.github.io/tags/other"><span class="label label-success">other</span></a>
			
				<a href="http://alanmoment.github.io/tags/octopress"><span class="label label-success">octopress</span></a>
			
				<a href="http://alanmoment.github.io/tags/git"><span class="label label-success">git</span></a>
			
		</small>
		
	</div>
</div>



<div class="text-center center-block">
	
    
    <ul class="pagination">
        
        <li>
            <a href="/" aria-label="First"><span aria-hidden="true">&laquo;&laquo;</span></a>
        </li>
        
        <li
        >
        <a href="/page/4/" aria-label="Previous"><span aria-hidden="true">&laquo;</span></a>
        </li>
        
        <li
        ><a href="/">1</a></li>
        
        <li
        ><a href="/page/2/">2</a></li>
        
        <li
        ><a href="/page/3/">3</a></li>
        
        <li
        ><a href="/page/4/">4</a></li>
        
        <li
        class="active"><a href="/page/5/">5</a></li>
        
        <li
        class="disabled">
        <a href="" aria-label="Next"><span aria-hidden="true">&raquo;</span></a>
        </li>
        
        <li>
            <a href="/page/5/" aria-label="Last"><span aria-hidden="true">&raquo;&raquo;</span></a>
        </li>
        
    </ul>
    
</div>

						</div>
					</div>
				</div>
			</div>
		</div>
  </div>
  
  <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.2/js/bootstrap.min.js"></script>
  
  <script src="//cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/topojson/1.6.9/topojson.min.js"></script>
  
  
  <script src="http://alanmoment.github.io//js/App.js"></script>
  
</body>
</html>